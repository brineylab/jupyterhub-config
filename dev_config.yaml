# This file can update the JupyterHub Helm chart's default configuration values.
#
# For reference see the configuration reference and default values, but make
# sure to refer to the Helm chart version of interest to you!
#
# Introduction to YAML:     https://www.youtube.com/watch?v=cdLNKUoMc6c
# Chart config reference:   https://zero-to-jupyterhub.readthedocs.io/en/stable/resources/reference.html
# Chart default values:     https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/HEAD/jupyterhub/values.yaml
# Available chart versions: https://jupyterhub.github.io/helm-chart/

# disable user and server culling
cull:
  enabled: false

# from https://z2jh.jupyter.org/en/stable/administrator/optimization.html
scheduling:
  userScheduler:
    enabled: false

# Update images here
# NOTE: Images need to be updated in a second place in this file.
#       This only updates the image puller, so that new images get
#       pulled during the helm upgrade.
prePuller:
  extraImages:
    datascience:
      name: brineylab/jupyterhub-datascience
      tag: v2024-08-13
    deeplearning:
      name: brineylab/jupyterhub-deeplearning
      tag: v2024-08-13

singleuser:
  cmd: jupyterhub-singleuser
  defaultUrl: lab

  # networking (notebook server spawning fails if networkPolicy is set to true)
  networkPolicy:
    enabled: false

  # set extra environmental vars
  extraEnv:
    GRANT_SUDO: "yes"
  uid: 0
  fsGid: 0

  # defaults - in case pods get launched w/o specifying profile
  # i think this can only happen from the admin page
  memory:
    limit: 16G
    guarantee: 4G
  cpu:
    limit: 16
    guarantee: 4
  image:
    name: "brineylab/jupyterhub-datascience"
    tag: "v2024-08-13"

  # required for codeserver to launch
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "sh"
          - "-c"
          - >
            mkdir -p ${HOME}/codeserver;
            mkdir -p ${HOME}/.local;
            chown -R ${NB_UID:-1000}:${NB_GID:-100} ${HOME}/codeserver;
            chown -R ${NB_UID:-1000}:${NB_GID:-100} ${HOME}/.local;

  storage:
    dynamic:
      storageClass: nfs-rym-jh-sata
    capacity: 100Gi

    # extraVolumes:
    #   # shared
    #   - name:  nfs-wallace-shared
    #     persistentVolumeClaim:
    #       claimName: nfs-wallace-shared
    #   # references
    #   - name: nfs-wallace-references
    #     persistentVolumeClaim:
    #       claimName: nfs-wallace-references
    #       readOnly: true
    #   # sequencing data: NovaSeq
    #   - name: nfs-avon-novaseq6k
    #     persistentVolumeClaim:
    #       claimName: nfs-avon-novaseq6k
    #   # sequencing data: NextSeq
    #   - name: nfs-avon-nextseq2k
    #     persistentVolumeClaim:
    #       claimName: nfs-avon-nextseq2k
    #   # sequencing data: ONT
    #   - name: nfs-stringer-ont
    #     persistentVolumeClaim:
    #       claimName: nfs-stringer-ont
    #   # dshm - needed for training on gpu servers running jupyterhub
    #   - name: dshm
    #     emptyDir:
    #       medium: Memory
    #       sizeLimit: "10Gi"
    # extraVolumeMounts:
    #   - name: nfs-wallace-shared
    #     mountPath: /home/jovyan/shared
    #   - name: nfs-wallace-references
    #     mountPath: /home/jovyan/references
    #   - name: nfs-avon-novaseq6k
    #     mountPath: /home/jovyan/sequencing_runs/novaseq
    #   - name: nfs-avon-nextseq2k
    #     mountPath: /home/jovyan/sequencing_runs/nextseq
    #   - name: nfs-stringer-ont
    #     mountPath: /home/jovyan/sequencing_runs/ont
    #   - name: dshm
    #     mountPath: /dev/shm

hub:
  networkPolicy:
    enabled: false
  
  # needs to be non-root user (root is 0): https://discourse.jupyter.org/t/customizing-jupyterhub-on-kubernetes/1769/39
  containerSecurityContext:
    runAsUser: 1000 
    runAsGroup: 0
  
  # change hub database to postgresql (default sqlite not compatible with NFS)
  # https://jupyterhub.readthedocs.io/en/latest/explanation/database.html#sqlite
  db:
    upgrade: true
    type: postgres
    url: "postgresql://brineylab:@192.168.1.1:5432/jupyterhub_db"
  
  extraEnv:
    PGPASSWORD: # will automatically provide password when env variable is named PGPASSWORD
      valueFrom:
        secretKeyRef:
          name: postgres-secret
          key: POSTGRES_PASSWORD

  # Mount users and home page configmaps
  extraVolumes:
    - name: templates
      configMap:
        name: templates
    - name: extra-config
      configMap:
        name: extra-config
  extraVolumeMounts:
    - mountPath: /etc/jupyterhub/templates
      name: templates
    - mountPath: /etc/jupyterhub/config
      name: extra-config

  config:
    JupyterHub:
      authenticator_class: "nativeauthenticator.NativeAuthenticator"
      default_url: "/hub/home"

    NativeAuthenticator:
      enable_signup: true

  extraConfig:
    # set env variables
    env: |
      c.KubeSpawner.environment = {'NB_UMASK': '0000'}
      c.KubeSpawner.allow_privilege_escalation = True
      c.KubeSpawner.args = ["--allow-root"]
    
    # custom templates
    templates: |
      import os, nativeauthenticator

      # inject custom templates
      c.JupyterHub.template_paths = ["/etc/jupyterhub/templates", 
                                      f"{os.path.dirname(nativeauthenticator.__file__)}/templates/"]

      # set url for gpu status
      c.JupyterHub.template_vars.update({
          "gpu_status_url": "http://172.29.180.91:5000/gpu_status_bynode"
      })

      # ref: https://github.com/jupyterhub/kubespawner/blob/main/kubespawner/spawner.py#L1699
      # bootstrap updated to v5 -> removes the 'hidden' class, need to use 'd-none' instead
      # kubespawner hasn't updated their html template with this fix as of Feb 24th 2025
      c.KubeSpawner.additional_profile_form_template_paths = "/etc/jupyterhub/templates"

    # set admin and allowed users -> allow admin and gpu users only
    users: |
      import yaml
      with open("/etc/jupyterhub/config/users.yaml") as f:
        users = yaml.safe_load(f)

      c.Authenticator.admin_users = users.get("admin", [])
      c.Authenticator.allowed_users = set(users.get("admin", []) + users.get("gpu", []) + users.get("regular", [])) 

    # custom named server limit
    # ref: https://jupyterhub.readthedocs.io/en/stable/howto/configuration/config-user-env.html#named-servers
    namedServers: |
      def custom_named_server_limit(handler):
        with open("/etc/jupyterhub/config/users.yaml") as f:
          users = yaml.safe_load(f)

        user = handler.current_user.name

        if user in users.get("admin", []):
            return 0 # unlimited
        elif user in users.get("gpu", []):
            return 2 # 3 servers total

        return 1 # 2 servers total

      c.JupyterHub.allow_named_servers = True
      c.JupyterHub.named_server_limit_per_user = custom_named_server_limit

    options-form: |
      import yaml
      import sys

      # import functions
      sys.path.append('/etc/jupyterhub/config')
      from options_form import dynamic_options_form_withconfig
      from prespawn_hook import set_spawner_resources

      # read node info
      with open("/etc/jupyterhub/config/nodes.yaml", "r") as file:
        node_info = yaml.safe_load(file)

      # update images and options for number of GPUs here
      CONFIG = {
        "images": {
            "datascience": "brineylab/jupyterhub-datascience:v2024-08-13",
            "deeplearning": "brineylab/jupyterhub-deeplearning:v2024-08-13",
        },
        "gpu_counts": [1, 2, 4, 8],
        "node_info": node_info["dev"],
        "server_type": "gpu-only" # can be: "cpu-gpu", "cpu-only", and "gpu-only"
      }
      
      # options for users to select from
      c.KubeSpawner.options_form = dynamic_options_form_withconfig(CONFIG)

      # pre-spawn hook to set resource limits based on user selections
      c.KubeSpawner.pre_spawn_hook = lambda spawner: set_spawner_resources(spawner, CONFIG)