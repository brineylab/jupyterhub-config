# This file can update the JupyterHub Helm chart's default configuration values.
#
# For reference see the configuration reference and default values, but make
# sure to refer to the Helm chart version of interest to you!
#
# Introduction to YAML:     https://www.youtube.com/watch?v=cdLNKUoMc6c
# Chart config reference:   https://zero-to-jupyterhub.readthedocs.io/en/stable/resources/reference.html
# Chart default values:     https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/HEAD/jupyterhub/values.yaml
# Available chart versions: https://jupyterhub.github.io/helm-chart/

# disable user and server culling
cull:
  enabled: false

# from https://z2jh.jupyter.org/en/stable/administrator/optimization.html
scheduling:
  userScheduler:
    enabled: false

# Update images here
# NOTE: Images need to be updated in a second place in this file.
#       This only updates the image puller, so that new images get
#       pulled during the helm upgrade.
prePuller:
  extraImages:
    datascience:
      name: brineylab/jupyterhub-datascience
      tag: v2024-05-23
    deeplearning:
      name: brineylab/jupyterhub-deeplearning
      tag: v2024-05-23

singleuser:
  cmd: jupyterhub-singleuser
  defaultUrl: lab

  # networking (notebook server spawning fails if networkPolicy is set to true)
  networkPolicy:
    enabled: false

  # set extra environmental vars
  extraEnv:
    GRANT_SUDO: "yes"
  uid: 0
  fsGid: 0

  # default resource limits
  memory:
    limit: 512G
    guarantee: 64G
  cpu:
    limit: 128
    guarantee: 16

  # required for codeserver to launch
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "sh"
          - "-c"
          - >
            mkdir -p ${HOME}/codeserver;
  
  storage:
    dynamic:
      storageClass: nfs-wallace-jh-nvme
    capacity: 250Gi

    extraVolumes:
      # shared
      - name:  nfs-wallace-shared
        persistentVolumeClaim:
          claimName: nfs-wallace-shared
      # references
      - name: nfs-wallace-references
        persistentVolumeClaim:
          claimName: nfs-wallace-references
          readOnly: true
      # sequencing data: NovaSeq
      - name: nfs-avon-novaseq6k
        persistentVolumeClaim:
          claimName: nfs-avon-novaseq6k
      # sequencing data: NextSeq
      - name: nfs-avon-nextseq2k
        persistentVolumeClaim:
          claimName: nfs-avon-nextseq2k
      # sequencing data: ONT
      - name: nfs-stringer-ont
        persistentVolumeClaim:
          claimName: nfs-stringer-ont
      # dshm - needed for training on gpu servers running jupyterhub
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: "10Gi"
    extraVolumeMounts:
      - name: nfs-wallace-shared
        mountPath: /home/jovyan/shared
      - name: nfs-wallace-references
        mountPath: /home/jovyan/references
      - name: nfs-avon-novaseq6k
        mountPath: /home/jovyan/sequencing_runs/novaseq
      - name: nfs-avon-nextseq2k
        mountPath: /home/jovyan/sequencing_runs/nextseq
      - name: nfs-stringer-ont
        mountPath: /home/jovyan/sequencing_runs/ont
      - name: dshm
        mountPath: /dev/shm

hub:
  networkPolicy:
    enabled: false
  
  containerSecurityContext:
    runAsUser: 0
    runAsGroup: 0

  # Mount users and home page configmaps
  extraVolumes:
    - name: jupyterhub-custom-templates
      configMap:
        name: jupyterhub-custom-templates
    - name: users-config
      configMap:
        name: users-config   
  extraVolumeMounts:
    - mountPath: /etc/jupyterhub/templates
      name: jupyterhub-custom-templates
    - mountPath: /etc/jupyterhub/auth
      name: users-config

  config:
    JupyterHub:
      authenticator_class: "nativeauthenticator.NativeAuthenticator"
      default_url: "/hub/home"

    NativeAuthenticator:
      enable_signup: true

  extraConfig:
    env: |
      c.KubeSpawner.environment = {'NB_UMASK': '0000'}
      c.KubeSpawner.allow_privilege_escalation = True
      c.KubeSpawner.args = ["--allow-root"]
    
    templates: |
      import os, nativeauthenticator
      c.JupyterHub.template_paths = [f"{os.path.dirname(nativeauthenticator.__file__)}/templates/"]
      c.JupyterHub.template_paths.insert(0, "/etc/jupyterhub/templates")

    users: |
      import yaml
      with open("/etc/jupyterhub/auth/users.yaml") as f:
        users = yaml.safe_load(f)

      c.Authenticator.admin_users = users.get("admin", [])
      c.Authenticator.allowed_users = set(users.get("admin", []) + users.get("gpu", []) + users.get("regular", [])) 

    # ref: https://jupyterhub.readthedocs.io/en/stable/howto/configuration/config-user-env.html#named-servers
    # src code: https://github.com/jupyterhub/jupyterhub/blob/main/jupyterhub/app.py#L1341
    namedServers: |
      def custom_named_server_limit(handler):
        with open("/etc/jupyterhub/auth/users.yaml") as f:
          users = yaml.safe_load(f)
        
        user = handler.current_user.name
        three_servers = set(users.get("admin", []) + users.get("gpu", []))
        if user in three_servers:
            return 2
        return 1

      c.JupyterHub.allow_named_servers = True
      c.JupyterHub.named_server_limit_per_user = custom_named_server_limit
    
    # modified from https://github.com/neurohackademy/nh2020-jupyterhub/blob/8bc0d8304d5090d3a1e21a038a68f0a940e31809/deployments/hub-neurohackademy-org/config/prod.yaml
    # ref for profile_options: https://jupyterhub-kubespawner.readthedocs.io/en/latest/spawner.html
    options-form: |
        
        # Define num of GPU options
        def define_gpu_options(option_list):
          return {
            "GPUs": {
              "display_name": "Number of GPUs",
              "choices": {
                str(i): {
                  "display_name": str(i),
                  # required to enable gpu: https://discourse.jupyter.org/t/set-runtimeclassname-for-gpu-enabled-images/21617/5
                  "kubespawner_override": {
                    "extra_resource_limits": {"nvidia.com/gpu": i},
                    "extra_pod_config": {"runtimeClassName": "nvidia"},
                  },
                } for i in option_list
              },
            }
          }
        
        # Define admin options for dev image
        def admin_options(deeplearning, datascience):
          gpu_types = ["cpu", "L40S", "A30", "A6000"]
          gpu_num = [0, 1, 2, 4, 8]
          return {
            "Image": {
              "display_name": "Image",
              "choices": {
                "deeplearning": {
                  "display_name": "default deeplearning",
                  "kubespawner_override": {"image": deeplearning,},
                },
                "datascience": {
                  "display_name": "default datascience",
                  "kubespawner_override": {"image": datascience},
                }
              },
              "unlisted_choice": {
                "enabled": True,
                "display_name": "Enter custom image",
                "display_name_in_choices": "Custom image",
                "validation_regex": '^.+/.+:.+$',
                "validation_message": 'Must be an image matching <user>/<name>:<tag>',
                "kubespawner_override": {
                  "image": "{value}",
                  "start_timeout": 600, # increase timeout time to 10mins to allow new images to be pulled
                },
              },
            },
            "GPU Type": {
              "display_name": "Type of GPU (or CPU only)",
              "choices": {
                str(i): {
                  "display_name": str(i),
                  "kubespawner_override": {
                    "node_selector": {"node_profile": i},
                  },
                } for i in gpu_types
              },
            },
            "GPU Num": {
              "display_name": "Number of GPUs",
              "choices": {
                str(i): {
                  "display_name": str(i),
                  # required to enable gpu: https://discourse.jupyter.org/t/set-runtimeclassname-for-gpu-enabled-images/21617/5
                  "kubespawner_override": {
                    "extra_resource_limits": {"nvidia.com/gpu": i},
                    "extra_pod_config": {"runtimeClassName": "nvidia"} if i > 0 else {},
                  },
                } for i in gpu_num
              },
            },
          }
        
        async def dynamic_options_form(self):
            
            # Update images here
            datascience = "brineylab/jupyterhub-datascience:v2024-08-13"
            deeplearning = "brineylab/jupyterhub-deeplearning:v2024-08-13"

            # Update gpu users here
            import yaml
            with open("/etc/jupyterhub/auth/users.yaml") as f:
              users = yaml.safe_load(f)
            gpu = users.get("gpu", [])
            
            # For default server -> CPU profiles
            if not self.name:
              self.profile_list = [
                {
                  "display_name": "data science",
                  "description": "default data analysis environment, including interpreters for Python and R <br> v2024-08-13",
                  "default": True,
                  "kubespawner_override": {
                      "image": datascience,
                      "node_selector": {"node_profile": "cpu"},
                  }
                },
                {
                  "display_name": "deep learning",
                  "description": "extends the data science environment to include ML libraries (such as torch, deepspeed, and ðŸ¤—) <br> v2024-08-13",
                  "kubespawner_override": {
                      "image": deeplearning,
                      "node_selector": {"node_profile": "cpu"},
                  }
                }
              ]
            
            # For named server(s) -> GPU profiles
            else:
              # add inference gpus for all users on named servers
              self.profile_list = [
                {
                  "display_name": "deep learning - A30 GPU",
                  "description": "One A30 GPU for inference and testing.",
                  "kubespawner_override": {
                    "image": deeplearning,
                    "node_selector": {"node_profile": "A30"},
                    "extra_resource_limits": {"nvidia.com/gpu": 1},
                    "extra_pod_config": {"runtimeClassName": "nvidia"},
                    "cpu_guarantee": 12,
                    "cpu_limit": 48,
                    "mem_guarantee": "12G",
                    "mem_limit": "64G"
                  },
                },
                {
                  "display_name": "deep learning - A6000 GPU",
                  "description": "One A6000 GPU for inference and testing.",
                  "kubespawner_override": {
                    "image": deeplearning,
                    "node_selector": {"node_profile": "A6000"},
                    "extra_resource_limits": {"nvidia.com/gpu": 1},
                    "extra_pod_config": {"runtimeClassName": "nvidia"},
                  },
                }
              ]

              # add L40s profiles for gpu users only
              if self.user.name in gpu or self.user.admin:
                self.profile_list.extend([
                  {
                    "display_name": "deep learning - L40s GPUs",
                    "description": "L40s GPUs - avaliable to GPU users only",
                    "kubespawner_override": {
                      "image": deeplearning,
                      "node_selector": {"node_profile": "L40S"},
                    },
                    "profile_options": define_gpu_options([1, 2, 4, 8]),
                  }
                ])
            
            # dev profile for admins only
            if self.user.admin:
              self.profile_list.extend([
                {
                  "display_name": "development",
                  "description": "Visible to admins only - can set custom images, resources, etc for testing.",
                  "profile_options": admin_options(deeplearning, datascience),
                }
              ])

            # NOTE: We let KubeSpawner inspect profile_list and decide what to
            #       return, it will return a falsy blank string if there is no
            #       profile_list, which makes no options form be presented.
            #
            # ref: https://github.com/jupyterhub/kubespawner/blob/37a80abb0a6c826e5c118a068fa1cf2725738038/kubespawner/spawner.py#L1885-L1935
            #
            return self._options_form_default()

        c.KubeSpawner.options_form = dynamic_options_form
